{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNSC. Mobile.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/murdockbleak/NN-Compression/blob/main/NNSC_Mobile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bavu9YCIcV2",
        "outputId": "34013892-56e8-430a-fde0-37508bdf386a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.7.1\n",
            "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 16 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2\n",
            "  Downloading torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 56.7 MB/s \n",
            "\u001b[?25hCollecting torchaudio==0.7.2\n",
            "  Downloading torchaudio-0.7.2-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 23.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.10.0+cu111\n",
            "    Uninstalling torchaudio-0.10.0+cu111:\n",
            "      Successfully uninstalled torchaudio-0.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.7.1 torchaudio-0.7.2 torchvision-0.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save ResNet models in Torchscript format"
      ],
      "metadata": {
        "id": "JPdnvaumIpus"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save ResNet model in TorchScript format"
      ],
      "metadata": {
        "id": "u90fM7TKvemt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCD6e8TBA_mv",
        "outputId": "603f68c9-3358-45dd-8706-e151cb516bcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model_generation_bs10.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model_generation_bs10.py\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.bundled_inputs import (\n",
        "  augment_model_with_bundled_inputs)\n",
        "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
        "\n",
        "# Load PyTorch model\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Generate input image\n",
        "example = torch.zeros(10, 3, 224, 224)\n",
        "\n",
        "# Save model graph to TorchScript format\n",
        "script_module = torch.jit.trace(model, example)\n",
        "\n",
        "# Optimize for mobile PyTorch operations that are supported by Android framework\n",
        "# If operations are not supported, they remain unchanged\n",
        "script_module_optimized = optimize_for_mobile(script_module)\n",
        "\n",
        "# Create a joint input consisting of model and input image\n",
        "augment_model_with_bundled_inputs(script_module_optimized, [(example,)])\n",
        "\n",
        "# Save binary file with model on the computer\n",
        "torch.jit.save(script_module_optimized, \"./resnet18_bs10.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRip8HsJBZAi",
        "outputId": "2a5a508a-8da8-4906-a4cb-c8adbc513910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_generation_bs10.py  model_generation_quantized.py  resnet18_quantized.pt\n",
            "model_generation.py\t  resnet18.pt\t\t\t sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python model_generation_bs10.py"
      ],
      "metadata": {
        "id": "Mpl2A2GZBbcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save quantized ResNet model in TorchScript format\n"
      ],
      "metadata": {
        "id": "0o9ivSaGvtXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_generation_quantized_bs10.py\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.bundled_inputs import (\n",
        "  augment_model_with_bundled_inputs)\n",
        "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
        "\n",
        "# Load PyTorch model\n",
        "model = torchvision.models.quantization.resnet18(pretrained=True, quantize=True)\n",
        "model.eval()\n",
        "\n",
        "# Generate input image\n",
        "example = torch.zeros(10, 3, 224, 224)\n",
        "\n",
        "# Save model graph to TorchScript format\n",
        "script_module = torch.jit.trace(model, example)\n",
        "\n",
        "\n",
        "# Optimize for mobile PyTorch operations that are supported by Android framework\n",
        "# If operations are not supported, they remain unchanged\n",
        "script_module_optimized = optimize_for_mobile(script_module)\n",
        "\n",
        "# Create a joint input consisting of model and input image\n",
        "augment_model_with_bundled_inputs(script_module_optimized, [(example,)])\n",
        "\n",
        "# Save binary file with model on the computer\n",
        "torch.jit.save(script_module_optimized, \"./resnet18_quantized_bs10.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYVTjF_gBfYn",
        "outputId": "7fbdbeea-9efb-42d1-ac0d-19c18fbefee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model_generation_quantized_bs10.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python model_generation_quantized_bs10.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOZia1FPRVv-",
        "outputId": "0e396a67-8cf4-4bc5-8411-7392893f98a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/quantization/observer.py:121: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  reduce_range will be deprecated in a future release of PyTorch.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare memory allocated by TorchScript models"
      ],
      "metadata": {
        "id": "zf6lweanzFRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " import os\n",
        " print('Size (MB):', os.path.getsize(\"resnet18_bs10.pt\") / 1024**2)\n",
        " print('Size (MB):', os.path.getsize(\"resnet18_quantized_bs10.pt\") / 1024**2)\n"
      ],
      "metadata": {
        "id": "M7hY0SNtyrXo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe35a63e-d95d-4434-81ef-504a3c53e279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size (MB): 44.59046459197998\n",
            "Size (MB): 11.284072875976562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare inference time of TorchScript models"
      ],
      "metadata": {
        "id": "XIZRQh6f0U2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "f_model = torch.jit.load('./resnet18.pt')\n",
        "q_model = torch.jit.load('./resnet18_quantized.pt')\n"
      ],
      "metadata": {
        "id": "1mOo6uU4zjOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn((1, 3, 224, 224))"
      ],
      "metadata": {
        "id": "qT6x5lW2BMn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit _ = f_model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaipARMMzyp4",
        "outputId": "2dc28fc7-88d1-4906-d1f4-13820f396fd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:727: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:848.)\n",
            "  result = self.forward(*input, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 75.7 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit _ = q_model(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvfIiT-Hz00N",
        "outputId": "c20d0909-b521-4e06-a32e-99ea447a2143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 32.4 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TorchScript records its definitions in an Intermediate Representation (or IR, commonly referred to in Deep learning as a graph. \n",
        "\n",
        "We can examine the graph with the .graph property:"
      ],
      "metadata": {
        "id": "uIyUAhoP2Si-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f_model.graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B6NOxRy12rG",
        "outputId": "a3f3f3e3-91ea-43f1-fe61-3460c6c21e9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "graph(%self.1 : __torch__.torchvision.models.resnet.___torch_mangle_332.ResNet,\n",
              "      %input.1 : Tensor):\n",
              "  %15 : bool = prim::Constant[value=0]() # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:586:0\n",
              "  %8 : int = prim::Constant[value=3]() # :0:0\n",
              "  %10 : int = prim::Constant[value=2]() # :0:0\n",
              "  %12 : int = prim::Constant[value=1]() # :0:0\n",
              "  %139 : int = prim::Constant[value=-1]() # /usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py:214:0\n",
              "  %3 : __torch__.torch.classes.xnnpack.Conv2dOpContext = prim::GetAttr[name=\"prepack_folding._jit_pass_packed_weight_0\"](%self.1)\n",
              "  %6 : Tensor = prepacked::conv2d_clamp_run(%input.1, %3)\n",
              "  %9 : int[] = prim::ListConstruct(%8, %8)\n",
              "  %11 : int[] = prim::ListConstruct(%10, %10)\n",
              "  %13 : int[] = prim::ListConstruct(%12, %12)\n",
              "  %14 : int[] = prim::ListConstruct(%12, %12)\n",
              "  %input0.1 : Tensor = aten::max_pool2d(%6, %9, %11, %13, %14, %15) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:586:0\n",
              "  %18 : __torch__.torch.classes.xnnpack.Conv2dOpContext = prim::GetAttr[name=\"prepack_folding._jit_pass_packed_weight_1\"](%self.1)\n",
              "  %21 : Tensor = prepacked::conv2d_clamp_run(%input0.1, %18)\n",
              "  %23 : __torch__.torch.classes.xnnpack.Conv2dOpContext = prim::GetAttr[name=\"prepack_folding._jit_pass_packed_weight_2\"](%self.1)\n",
              "  %26 : Tensor = prepacked::conv2d_clamp_run(%21, %23)\n",
              "  %29 : Tensor = aten::_add_relu_(%26, %input0.1, %12)\n",
              "  %31 : __torch__.torch.classes.xnnpack.Conv2dOpContext = prim::GetAttr[name=\"prepack_folding._jit_pass_packed_weight_3\"](%self.1)\n",
              "  %34 : Tensor = prepacked::conv2d_clamp_run(%29, %31)\n",
              "  %36 : __torch__.torch.classes.xnnpack.Conv2dOpContext = prim::GetAttr[name=\"prepack_folding._jit_pass_packed_weight_4\"](%self.1)\n",
              "  %39 : Tensor = prepacked::conv2d_clamp_run(%34, %36)\n",
              "  %42 : Tensor = aten::_add_relu_(%39, %29, %12)\n",
              "  %44 : __torch__.torch.classes.xnnpack.Conv2dOpContext = prim::GetAttr[name=\"prepack_folding._jit_pass_packed_weight_5\"](%self.1)\n",
              "  %47 : Tensor = prepacked::conv2d_clamp_run(%42, %44)\n",
              "  %49 : __torch__.torch.classes.xnnpack.Conv2dOpContext = prim::GetAttr[name=\"prepack_folding._jit_pass_packed_weight_6\"](%self.1)\n",
              "  %52 : Tensor = prepacked::conv2d_clamp_run(%47, %49)\n",
              "  %54 : __torch__.torch.classes.xnnpack.Conv2dOpContext = prim::GetAttr[name=\"prepack_folding._jit_pass_packed_weight_7\"](%self.1)\n",
              "  %57 : Tensor = prepacked::conv2d_clamp_run(%42, %54)\n",
              "  %60 : Tensor = aten::_add_relu_(%52, %57, %12)\n",
              "  %62 : __torch__.torch.classes.xnnpack.Conv2dOpContext = prim::GetAttr[name=\"prepack_folding._jit_pass_packed_weight_8\"](%self.1)\n",
              "  %65 : Tensor = prepacked::conv2d_clamp_run(%60, %62)\n",
              "  %67 : __torch__.torch.classes.xnnpack.Conv2dOpContext = prim::GetAttr[name=\"prepack_folding._jit_pass_packed_weight_9\"](%self.1)\n",
              "  %70 : Tensor = prepacked::conv2d_clamp_run(%65, %67)\n",
              "  %73 : Tensor = aten::_add_relu_(%70, %60, %12)\n",
              "  %75 : __torch__.torch.classes.xnnpack.Conv2dOpContext = prim::GetAttr[name=\"prepack_folding._jit_pass_packed_weight_10\"](%self.1)\n",
              "  %78 : Tensor = prepacked::conv2d_clamp_run(%73, %75)\n",
              "  %80 : __torch__.torch.classes.xnnpack.Conv2dOpContext = prim::GetAttr[name=\"prepack_folding._jit_pass_packed_weight_11\"](%self.1)\n",
              "  %83 : Tensor = prepacked::conv2d_clamp_run(%78, %80)\n",
              "  %85 : __torch__.torch.classes.xnnpack.Conv2dOpContext = prim::GetAttr[name=\"prepack_folding._jit_pass_packed_weight_12\"](%self.1)\n",
              "  %88 : Tensor = prepacked::conv2d_clamp_run(%73, %85)\n",
              "  %91 : Tensor = aten::_add_relu_(%83, %88, %12)\n",
              "  %93 : __torch__.torch.classes.xnnpack.Conv2dOpContext = prim::GetAttr[name=\"prepack_folding._jit_pass_packed_weight_13\"](%self.1)\n",
              "  %96 : Tensor = prepacked::conv2d_clamp_run(%91, %93)\n",
              "  %98 : __torch__.torch.classes.xnnpack.Conv2dOpContext = prim::GetAttr[name=\"prepack_folding._jit_pass_packed_weight_14\"](%self.1)\n",
              "  %101 : Tensor = prepacked::conv2d_clamp_run(%96, %98)\n",
              "  %104 : Tensor = aten::_add_relu_(%101, %91, %12)\n",
              "  %106 : __torch__.torch.classes.xnnpack.Conv2dOpContext = prim::GetAttr[name=\"prepack_folding._jit_pass_packed_weight_15\"](%self.1)\n",
              "  %109 : Tensor = prepacked::conv2d_clamp_run(%104, %106)\n",
              "  %111 : __torch__.torch.classes.xnnpack.Conv2dOpContext = prim::GetAttr[name=\"prepack_folding._jit_pass_packed_weight_16\"](%self.1)\n",
              "  %114 : Tensor = prepacked::conv2d_clamp_run(%109, %111)\n",
              "  %116 : __torch__.torch.classes.xnnpack.Conv2dOpContext = prim::GetAttr[name=\"prepack_folding._jit_pass_packed_weight_17\"](%self.1)\n",
              "  %119 : Tensor = prepacked::conv2d_clamp_run(%104, %116)\n",
              "  %122 : Tensor = aten::_add_relu_(%114, %119, %12)\n",
              "  %124 : __torch__.torch.classes.xnnpack.Conv2dOpContext = prim::GetAttr[name=\"prepack_folding._jit_pass_packed_weight_18\"](%self.1)\n",
              "  %127 : Tensor = prepacked::conv2d_clamp_run(%122, %124)\n",
              "  %129 : __torch__.torch.classes.xnnpack.Conv2dOpContext = prim::GetAttr[name=\"prepack_folding._jit_pass_packed_weight_19\"](%self.1)\n",
              "  %132 : Tensor = prepacked::conv2d_clamp_run(%127, %129)\n",
              "  %135 : Tensor = aten::_add_relu_(%132, %122, %12)\n",
              "  %136 : int[] = prim::ListConstruct(%12, %12)\n",
              "  %x.1 : Tensor = aten::adaptive_avg_pool2d(%135, %136) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:936:0\n",
              "  %input1.1 : Tensor = aten::flatten(%x.1, %12, %139) # /usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py:214:0\n",
              "  %142 : __torch__.torch.classes.xnnpack.LinearOpContext = prim::GetAttr[name=\"prepack_folding._jit_pass_packed_weight_20\"](%self.1)\n",
              "  %145 : Tensor = prepacked::linear_clamp_run(%input1.1, %142)\n",
              "  return (%145)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_model.graph"
      ],
      "metadata": {
        "id": "S14ruxB62Cxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, this is a very low-level representation and most of the information contained in the graph is not useful for end users. \n",
        "\n",
        "Instead, we can use the .code property to give a Python-syntax interpretation of the code"
      ],
      "metadata": {
        "id": "ijI3ypmZ2biW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f_model.code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "pkpy2pMc2Xvi",
        "outputId": "5479800d-74a8-49dc-d2c3-f4d8569f8a2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'def forward(self,\\n    input: Tensor) -> Tensor:\\n  _0 = getattr(self, \"prepack_folding._jit_pass_packed_weight_0\")\\n  _1 = ops.prepacked.conv2d_clamp_run(input, _0)\\n  input0 = torch.max_pool2d(_1, [3, 3], [2, 2], [1, 1], [1, 1], False)\\n  _2 = getattr(self, \"prepack_folding._jit_pass_packed_weight_1\")\\n  _3 = ops.prepacked.conv2d_clamp_run(input0, _2)\\n  _4 = getattr(self, \"prepack_folding._jit_pass_packed_weight_2\")\\n  _5 = ops.prepacked.conv2d_clamp_run(_3, _4)\\n  _6 = torch._add_relu_(_5, input0, alpha=1)\\n  _7 = getattr(self, \"prepack_folding._jit_pass_packed_weight_3\")\\n  _8 = ops.prepacked.conv2d_clamp_run(_6, _7)\\n  _9 = getattr(self, \"prepack_folding._jit_pass_packed_weight_4\")\\n  _10 = ops.prepacked.conv2d_clamp_run(_8, _9)\\n  _11 = torch._add_relu_(_10, _6, alpha=1)\\n  _12 = getattr(self, \"prepack_folding._jit_pass_packed_weight_5\")\\n  _13 = ops.prepacked.conv2d_clamp_run(_11, _12)\\n  _14 = getattr(self, \"prepack_folding._jit_pass_packed_weight_6\")\\n  _15 = ops.prepacked.conv2d_clamp_run(_13, _14)\\n  _16 = getattr(self, \"prepack_folding._jit_pass_packed_weight_7\")\\n  _17 = ops.prepacked.conv2d_clamp_run(_11, _16)\\n  _18 = torch._add_relu_(_15, _17, alpha=1)\\n  _19 = getattr(self, \"prepack_folding._jit_pass_packed_weight_8\")\\n  _20 = ops.prepacked.conv2d_clamp_run(_18, _19)\\n  _21 = getattr(self, \"prepack_folding._jit_pass_packed_weight_9\")\\n  _22 = ops.prepacked.conv2d_clamp_run(_20, _21)\\n  _23 = torch._add_relu_(_22, _18, alpha=1)\\n  _24 = getattr(self, \"prepack_folding._jit_pass_packed_weight_10\")\\n  _25 = ops.prepacked.conv2d_clamp_run(_23, _24)\\n  _26 = getattr(self, \"prepack_folding._jit_pass_packed_weight_11\")\\n  _27 = ops.prepacked.conv2d_clamp_run(_25, _26)\\n  _28 = getattr(self, \"prepack_folding._jit_pass_packed_weight_12\")\\n  _29 = ops.prepacked.conv2d_clamp_run(_23, _28)\\n  _30 = torch._add_relu_(_27, _29, alpha=1)\\n  _31 = getattr(self, \"prepack_folding._jit_pass_packed_weight_13\")\\n  _32 = ops.prepacked.conv2d_clamp_run(_30, _31)\\n  _33 = getattr(self, \"prepack_folding._jit_pass_packed_weight_14\")\\n  _34 = ops.prepacked.conv2d_clamp_run(_32, _33)\\n  _35 = torch._add_relu_(_34, _30, alpha=1)\\n  _36 = getattr(self, \"prepack_folding._jit_pass_packed_weight_15\")\\n  _37 = ops.prepacked.conv2d_clamp_run(_35, _36)\\n  _38 = getattr(self, \"prepack_folding._jit_pass_packed_weight_16\")\\n  _39 = ops.prepacked.conv2d_clamp_run(_37, _38)\\n  _40 = getattr(self, \"prepack_folding._jit_pass_packed_weight_17\")\\n  _41 = ops.prepacked.conv2d_clamp_run(_35, _40)\\n  _42 = torch._add_relu_(_39, _41, alpha=1)\\n  _43 = getattr(self, \"prepack_folding._jit_pass_packed_weight_18\")\\n  _44 = ops.prepacked.conv2d_clamp_run(_42, _43)\\n  _45 = getattr(self, \"prepack_folding._jit_pass_packed_weight_19\")\\n  _46 = ops.prepacked.conv2d_clamp_run(_44, _45)\\n  x = torch.adaptive_avg_pool2d(torch._add_relu_(_46, _42, alpha=1), [1, 1])\\n  input1 = torch.flatten(x, 1, -1)\\n  _47 = getattr(self, \"prepack_folding._jit_pass_packed_weight_20\")\\n  _48 = ops.prepacked.linear_clamp_run(input1, _47)\\n  return _48\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_model.code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "nYiL5mTH2rMm",
        "outputId": "858f550f-300b-4cd2-847c-07f00c27dfca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'def forward(self,\\n    X: Tensor) -> Tensor:\\n  _0 = self.fc\\n  input = torch.quantize_per_tensor(X, 0.037445519119501114, 57, 13)\\n  _1 = getattr(self, \"_jit_pass_hoist_conv_packed_params.conv1._packed_params.1\")\\n  input0 = ops.quantized.conv2d_relu(input, _1, 0.028605546802282333, 0)\\n  input1 = torch.max_pool2d(input0, [3, 3], [2, 2], [1, 1], [1, 1], False)\\n  _2 = getattr(self, \"_jit_pass_hoist_conv_packed_params.layer1.0.conv1._packed_params.2\")\\n  input2 = ops.quantized.conv2d_relu(input1, _2, 0.016524722799658775, 0)\\n  _3 = getattr(self, \"_jit_pass_hoist_conv_packed_params.layer1.0.conv2._packed_params.3\")\\n  x = ops.quantized.conv2d(input2, _3, 0.046455312520265579, 75)\\n  input3 = ops.quantized.add_relu(x, input1, 0.034476079046726227, 0)\\n  _4 = getattr(self, \"_jit_pass_hoist_conv_packed_params.layer1.1.conv1._packed_params.4\")\\n  input4 = ops.quantized.conv2d_relu(input3, _4, 0.017180869355797768, 0)\\n  _5 = getattr(self, \"_jit_pass_hoist_conv_packed_params.layer1.1.conv2._packed_params.5\")\\n  x0 = ops.quantized.conv2d(input4, _5, 0.065839782357215881, 82)\\n  input5 = ops.quantized.add_relu(x0, input3, 0.037044569849967957, 0)\\n  _6 = getattr(self, \"_jit_pass_hoist_conv_packed_params.layer2.0.conv1._packed_params.6\")\\n  input6 = ops.quantized.conv2d_relu(input5, _6, 0.014848409220576286, 0)\\n  _7 = getattr(self, \"_jit_pass_hoist_conv_packed_params.layer2.0.conv2._packed_params.7\")\\n  x1 = ops.quantized.conv2d(input6, _7, 0.043153878301382065, 58)\\n  _8 = getattr(self, \"_jit_pass_hoist_conv_packed_params.layer2.0.downsample.0._packed_params.8\")\\n  y = ops.quantized.conv2d(input5, _8, 0.033979002386331558, 68)\\n  input7 = ops.quantized.add_relu(x1, y, 0.025826521217823029, 0)\\n  _9 = getattr(self, \"_jit_pass_hoist_conv_packed_params.layer2.1.conv1._packed_params.9\")\\n  input8 = ops.quantized.conv2d_relu(input7, _9, 0.015309284441173077, 0)\\n  _10 = getattr(self, \"_jit_pass_hoist_conv_packed_params.layer2.1.conv2._packed_params.10\")\\n  x2 = ops.quantized.conv2d(input8, _10, 0.044221054762601852, 70)\\n  input9 = ops.quantized.add_relu(x2, input7, 0.032176367938518524, 0)\\n  _11 = getattr(self, \"_jit_pass_hoist_conv_packed_params.layer3.0.conv1._packed_params.11\")\\n  input10 = ops.quantized.conv2d_relu(input9, _11, 0.018436331301927567, 0)\\n  _12 = getattr(self, \"_jit_pass_hoist_conv_packed_params.layer3.0.conv2._packed_params.12\")\\n  x3 = ops.quantized.conv2d(input10, _12, 0.05117332935333252, 47)\\n  _13 = getattr(self, \"_jit_pass_hoist_conv_packed_params.layer3.0.downsample.0._packed_params.13\")\\n  y0 = ops.quantized.conv2d(input9, _13, 0.014961435459554195, 84)\\n  input11 = ops.quantized.add_relu(x3, y0, 0.027315333485603333, 0)\\n  _14 = getattr(self, \"_jit_pass_hoist_conv_packed_params.layer3.1.conv1._packed_params.14\")\\n  input12 = ops.quantized.conv2d_relu(input11, _14, 0.016513088718056679, 0)\\n  _15 = getattr(self, \"_jit_pass_hoist_conv_packed_params.layer3.1.conv2._packed_params.15\")\\n  x4 = ops.quantized.conv2d(input12, _15, 0.046813614666461945, 77)\\n  input13 = ops.quantized.add_relu(x4, input11, 0.026840999722480774, 0)\\n  _16 = getattr(self, \"_jit_pass_hoist_conv_packed_params.layer4.0.conv1._packed_params.16\")\\n  input14 = ops.quantized.conv2d_relu(input13, _16, 0.013452869839966297, 0)\\n  _17 = getattr(self, \"_jit_pass_hoist_conv_packed_params.layer4.0.conv2._packed_params.17\")\\n  x5 = ops.quantized.conv2d(input14, _17, 0.047327138483524323, 68)\\n  _18 = getattr(self, \"_jit_pass_hoist_conv_packed_params.layer4.0.downsample.0._packed_params.18\")\\n  y1 = ops.quantized.conv2d(input13, _18, 0.036629535257816315, 65)\\n  input15 = ops.quantized.add_relu(x5, y1, 0.029616426676511765, 0)\\n  _19 = getattr(self, \"_jit_pass_hoist_conv_packed_params.layer4.1.conv1._packed_params.19\")\\n  input16 = ops.quantized.conv2d_relu(input15, _19, 0.013848909176886082, 0)\\n  _20 = getattr(self, \"_jit_pass_hoist_conv_packed_params.layer4.1.conv2._packed_params.20\")\\n  x6 = ops.quantized.conv2d(input16, _20, 0.2509911060333252, 42)\\n  input17 = ops.quantized.add_relu(x6, input15, 0.17645132541656494, 0)\\n  x7 = torch.adaptive_avg_pool2d(input17, [1, 1])\\n  x8 = torch.flatten(x7, 1, -1)\\n  Xq = ops.quantized.linear(x8, _0._packed_params._packed_params, 0.2849271297454834, 35)\\n  return torch.dequantize(Xq)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why TorchScript?\n",
        "\n",
        "- TorchScript code can be invoked in its own interpreter, which is basically a restricted Python interpreter. \n",
        "\n",
        "- This interpreter does not acquire the Global Interpreter Lock, and so many requests can be processed on the same instance simultaneously.\n",
        "\n",
        "- This format allows us to save the whole model to disk and load it into another environment, such as in a server written in a language other than Python\n",
        "\n",
        "- TorchScript gives us a representation in which we can do compiler optimizations on the code to provide more efficient execution\n",
        "\n",
        "- TorchScript allows us to interface with many backend/device runtimes that require a broader view of the program than individual operators.\n",
        "\n",
        "- We can see that invoking traced model produces the same results as the Python module\n",
        "\n",
        "Inroduction to TorchScript: https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html\n"
      ],
      "metadata": {
        "id": "5QzUjJy05nZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare inference time and allocated memory of PyTorch models"
      ],
      "metadata": {
        "id": "4s1ZibVXwWw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "\n",
        "float_model = torchvision.models.resnet18()\n",
        "float_model.eval()\n",
        "for p in float_model.parameters():\n",
        "  p.requires_grad = False\n",
        "\n",
        "quantized_model = torchvision.models.quantization.resnet18(quantize=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyRhll2XM_yv",
        "outputId": "d3ae9cb5-2a6a-4940-f18b-53826d0944a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/quantization/observer.py:121: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  reduce_range will be deprecated in a future release of PyTorch.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_model.layer1[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "186OgEmAQuyR",
        "outputId": "7a5a440d-4f7a-48d3-def0-2fa3fe779aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BasicBlock(\n",
              "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantized_model.layer1[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExBwWw_dO7ev",
        "outputId": "d67421e2-7177-46d1-b010-5cc96b3c16a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuantizableBasicBlock(\n",
              "  (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.005704640876501799, zero_point=0, padding=(1, 1))\n",
              "  (bn1): Identity()\n",
              "  (relu): Identity()\n",
              "  (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.011008837260305882, zero_point=70, padding=(1, 1))\n",
              "  (bn2): Identity()\n",
              "  (add_relu): QFunctional(\n",
              "    scale=0.007786150556057692, zero_point=0\n",
              "    (activation_post_process): Identity()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(10, 3, 224, 224)"
      ],
      "metadata": {
        "id": "QG_cCssrxBgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit float_model(x) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXV-WO7XRzZk",
        "outputId": "ce0bd8e8-10d0-4b07-bda9-5464845c3974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 781 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit quantized_model(x) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dld1mO91PJaC",
        "outputId": "6933f864-84ff-44b2-bbed-91a953b4eb90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 561 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_size_of_model(model):\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    print('Size (MB):', os.path.getsize(\"temp.p\") / 1024**2)\n",
        "    os.remove('temp.p')"
      ],
      "metadata": {
        "id": "8Vqc7FVjxIOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_size_of_model(float_model)\n",
        "print_size_of_model(quantized_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r272KmGIzesM",
        "outputId": "10fd6f35-5b1f-4455-c4fe-02d46d75f311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size (MB): 44.667840003967285\n",
            "Size (MB): 11.293700218200684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ctB8ejNI3j2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compress with MusCO"
      ],
      "metadata": {
        "id": "mzUOsfaIKK1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorly==0.4.5\n",
        "!pip install git+https://github.com/musco-ai/musco-pytorch.git@develop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "421u_CBLK1v8",
        "outputId": "30a41d2a-02a5-46d1-c841-dbfc60be46ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorly==0.4.5\n",
            "  Downloading tensorly-0.4.5.tar.gz (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorly==0.4.5) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tensorly==0.4.5) (1.4.1)\n",
            "Collecting nose\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[K     |████████████████████████████████| 154 kB 17.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: tensorly\n",
            "  Building wheel for tensorly (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorly: filename=tensorly-0.4.5-py3-none-any.whl size=100163 sha256=f661fab41223a47c22d07b3cb844e5c6a2472a4a7ea0f833d43968468ea20dbd\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/ed/36/493bba3faa150a1193eec864db4951355eb64659330cb00722\n",
            "Successfully built tensorly\n",
            "Installing collected packages: nose, tensorly\n",
            "Successfully installed nose-1.3.7 tensorly-0.4.5\n",
            "Collecting git+https://github.com/musco-ai/musco-pytorch.git@develop\n",
            "  Cloning https://github.com/musco-ai/musco-pytorch.git (to revision develop) to /tmp/pip-req-build-isshlnhj\n",
            "  Running command git clone -q https://github.com/musco-ai/musco-pytorch.git /tmp/pip-req-build-isshlnhj\n",
            "  Running command git checkout -b develop --track origin/develop\n",
            "  Switched to a new branch 'develop'\n",
            "  Branch 'develop' set up to track remote branch 'develop' from 'origin'.\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from musco-pytorch==1.0.6) (1.4.1)\n",
            "Collecting scikit-tensor-py3\n",
            "  Downloading scikit_tensor_py3-0.4.1-py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from musco-pytorch==1.0.6) (0.12.0)\n",
            "Collecting flopco-pytorch\n",
            "  Downloading flopco_pytorch-0.1.4-py3-none-any.whl (4.6 kB)\n",
            "Requirement already satisfied: tensorly==0.4.5 in /usr/local/lib/python3.7/dist-packages (from musco-pytorch==1.0.6) (0.4.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorly==0.4.5->musco-pytorch==1.0.6) (1.19.5)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.7/dist-packages (from tensorly==0.4.5->musco-pytorch==1.0.6) (1.3.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->musco-pytorch==1.0.6) (1.15.0)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.3.3-cp37-cp37m-manylinux1_x86_64.whl (25.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.2 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting numpy\n",
            "  Downloading numpy-1.16.6-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 547 kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: musco-pytorch\n",
            "  Building wheel for musco-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for musco-pytorch: filename=musco_pytorch-1.0.6-py3-none-any.whl size=27692 sha256=646adc0407a0c3c5a48f90d93e767c08b7c56b266ac312ead565c9943bb2bda4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-oszqpwas/wheels/20/47/73/e81ca072181e9a2dc64a1b84d046b6a5934cd378f7431fe42b\n",
            "Successfully built musco-pytorch\n",
            "Installing collected packages: numpy, scipy, scikit-tensor-py3, flopco-pytorch, musco-pytorch\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 0.18.2 requires numpy>=1.17, but you have numpy 1.16.6 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
            "pywavelets 1.2.0 requires numpy>=1.17.3, but you have numpy 1.16.6 which is incompatible.\n",
            "pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.16.6 which is incompatible.\n",
            "kapre 0.3.6 requires numpy>=1.18.5, but you have numpy 1.16.6 which is incompatible.\n",
            "jaxlib 0.1.71+cuda111 requires numpy>=1.18, but you have numpy 1.16.6 which is incompatible.\n",
            "jax 0.2.25 requires numpy>=1.18, but you have numpy 1.16.6 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "cupy-cuda111 9.4.0 requires numpy<1.24,>=1.17, but you have numpy 1.16.6 which is incompatible.\n",
            "astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.16.6 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed flopco-pytorch-0.1.4 musco-pytorch-1.0.6 numpy-1.16.6 scikit-tensor-py3-0.4.1 scipy-1.3.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet18\n",
        "from flopco import FlopCo\n",
        "from musco.pytorch import Compressor\n",
        "from musco.pytorch.compressor.utils import standardize_model\n",
        "import copy"
      ],
      "metadata": {
        "id": "wpkX8CaJKh8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "?  Compressor"
      ],
      "metadata": {
        "id": "jVkJZX_QMpjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'\n",
        "\n",
        "# Load the model\n",
        "model = resnet18(pretrained=True).to(device)\n",
        "\n",
        "# Collect initial model statistics\n",
        "model_stats = FlopCo(model,\n",
        "                     img_size = (1, 3, 128, 128),\n",
        "                     device = device)\n",
        "\n",
        "# Set a model compression schedule\n",
        "# model_compr_kwargs = {\n",
        "#     'layer3.1.conv2': {'decomposition': 'tucker2',\n",
        "#                        'rank_selection': 'manual',\n",
        "#                        'manual_rank': [(32, 32), (16, 16)],\n",
        "#                        'curr_compr_iter': 0\n",
        "#                       },\n",
        "#     'layer2.1.conv2': {'decomposition': 'tucker2',\n",
        "#                        'rank_selection': 'vbmf',\n",
        "#                        'vbmf_weakenen_factor': 0.9,\n",
        "#                        'curr_compr_iter': 0\n",
        "#                       },\n",
        "#     'fc': {'decomposition': 'svd',\n",
        "#                       'rank_selection': 'param_reduction',\n",
        "#                       'param_reduction_rate': 4,\n",
        "#                       'curr_compr_iter': 0\n",
        "#                       },\n",
        "# }\n",
        "\n",
        "\n",
        "# Initialize a compressor\n",
        "compressor = Compressor(copy.deepcopy(model),\n",
        "                        model_stats,\n",
        "                        ft_every=100,\n",
        "                        nglobal_compress_iters=1,\n",
        "                        # model_compr_kwargs = model_compr_kwargs,\n",
        "                        config_type = 'vbmf'\n",
        "                        )\n",
        "\n",
        "\n",
        "# Alernate compression and fine-tuning steps, while compression is not done\n",
        "# (i.e., until each compressing layer is compressed `nglobal_compress_iters` times)\n",
        "while not compressor.done:\n",
        "            # Compress layers\n",
        "            compressor.compression_step()\n",
        "\n",
        "            # Fine-tune compressor.compressed_model\n",
        "\n",
        "# Replace custom layers with standard nn.Module layers.\n",
        "standardize_model(compressor.compressed_model)\n",
        "\n",
        "# compressor.compressed_model is our final compressed and standardized model.\n",
        "compressor.compressed_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YZ_F7PELagw",
        "outputId": "126ab8aa-deb5-4f67-f39d-6e1187b835af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1 defaultdict(None, {'decomposition': 'tucker2', 'rank_selection': 'vbmf', 'manual_rank': None, 'param_reduction_rate': None, 'vbmf_weakenen_factor': 0.8, 'curr_compr_iter': 0})\n",
            "layer1.0.conv1 defaultdict(None, {'decomposition': 'tucker2', 'rank_selection': 'vbmf', 'manual_rank': None, 'param_reduction_rate': None, 'vbmf_weakenen_factor': 0.8, 'curr_compr_iter': 0})\n",
            "layer1.0.conv2 defaultdict(None, {'decomposition': 'tucker2', 'rank_selection': 'vbmf', 'manual_rank': None, 'param_reduction_rate': None, 'vbmf_weakenen_factor': 0.8, 'curr_compr_iter': 0})\n",
            "layer1.1.conv1 defaultdict(None, {'decomposition': 'tucker2', 'rank_selection': 'vbmf', 'manual_rank': None, 'param_reduction_rate': None, 'vbmf_weakenen_factor': 0.8, 'curr_compr_iter': 0})\n",
            "layer1.1.conv2 defaultdict(None, {'decomposition': 'tucker2', 'rank_selection': 'vbmf', 'manual_rank': None, 'param_reduction_rate': None, 'vbmf_weakenen_factor': 0.8, 'curr_compr_iter': 0})\n",
            "layer2.0.conv1 defaultdict(None, {'decomposition': 'tucker2', 'rank_selection': 'vbmf', 'manual_rank': None, 'param_reduction_rate': None, 'vbmf_weakenen_factor': 0.8, 'curr_compr_iter': 0})\n",
            "layer2.0.conv2 defaultdict(None, {'decomposition': 'tucker2', 'rank_selection': 'vbmf', 'manual_rank': None, 'param_reduction_rate': None, 'vbmf_weakenen_factor': 0.8, 'curr_compr_iter': 0})\n",
            "layer2.0.downsample.0 defaultdict(None, {'decomposition': 'svd', 'rank_selection': 'vbmf', 'manual_rank': None, 'param_reduction_rate': None, 'vbmf_weakenen_factor': 0.8, 'curr_compr_iter': 0})\n",
            "layer2.1.conv1 defaultdict(None, {'decomposition': 'tucker2', 'rank_selection': 'vbmf', 'manual_rank': None, 'param_reduction_rate': None, 'vbmf_weakenen_factor': 0.8, 'curr_compr_iter': 0})\n",
            "layer2.1.conv2 defaultdict(None, {'decomposition': 'tucker2', 'rank_selection': 'vbmf', 'manual_rank': None, 'param_reduction_rate': None, 'vbmf_weakenen_factor': 0.8, 'curr_compr_iter': 0})\n",
            "layer3.0.conv1 defaultdict(None, {'decomposition': 'tucker2', 'rank_selection': 'vbmf', 'manual_rank': None, 'param_reduction_rate': None, 'vbmf_weakenen_factor': 0.8, 'curr_compr_iter': 0})\n",
            "layer3.0.conv2 defaultdict(None, {'decomposition': 'tucker2', 'rank_selection': 'vbmf', 'manual_rank': None, 'param_reduction_rate': None, 'vbmf_weakenen_factor': 0.8, 'curr_compr_iter': 0})\n",
            "layer3.0.downsample.0 defaultdict(None, {'decomposition': 'svd', 'rank_selection': 'vbmf', 'manual_rank': None, 'param_reduction_rate': None, 'vbmf_weakenen_factor': 0.8, 'curr_compr_iter': 0})\n",
            "layer3.1.conv1 defaultdict(None, {'decomposition': 'tucker2', 'rank_selection': 'vbmf', 'manual_rank': None, 'param_reduction_rate': None, 'vbmf_weakenen_factor': 0.8, 'curr_compr_iter': 0})\n",
            "layer3.1.conv2 defaultdict(None, {'decomposition': 'tucker2', 'rank_selection': 'vbmf', 'manual_rank': None, 'param_reduction_rate': None, 'vbmf_weakenen_factor': 0.8, 'curr_compr_iter': 0})\n",
            "layer4.0.conv1 defaultdict(None, {'decomposition': 'tucker2', 'rank_selection': 'vbmf', 'manual_rank': None, 'param_reduction_rate': None, 'vbmf_weakenen_factor': 0.8, 'curr_compr_iter': 0})\n",
            "layer4.0.conv2 defaultdict(None, {'decomposition': 'tucker2', 'rank_selection': 'vbmf', 'manual_rank': None, 'param_reduction_rate': None, 'vbmf_weakenen_factor': 0.8, 'curr_compr_iter': 0})\n",
            "layer4.0.downsample.0 defaultdict(None, {'decomposition': 'svd', 'rank_selection': 'vbmf', 'manual_rank': None, 'param_reduction_rate': None, 'vbmf_weakenen_factor': 0.8, 'curr_compr_iter': 0})\n",
            "layer4.1.conv1 defaultdict(None, {'decomposition': 'tucker2', 'rank_selection': 'vbmf', 'manual_rank': None, 'param_reduction_rate': None, 'vbmf_weakenen_factor': 0.8, 'curr_compr_iter': 0})\n",
            "layer4.1.conv2 defaultdict(None, {'decomposition': 'tucker2', 'rank_selection': 'vbmf', 'manual_rank': None, 'param_reduction_rate': None, 'vbmf_weakenen_factor': 0.8, 'curr_compr_iter': 0})\n",
            "fc defaultdict(None, {'decomposition': 'svd', 'rank_selection': 'vbmf', 'manual_rank': None, 'param_reduction_rate': None, 'vbmf_weakenen_factor': 0.8, 'curr_compr_iter': 0})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Sequential(\n",
              "    (conv1-0): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (conv1-1): Conv2d(3, 36, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (conv1-2): Conv2d(36, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  )\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Sequential(\n",
              "        (conv1-0): Conv2d(64, 44, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv1-1): Conv2d(44, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv1-2): Conv2d(36, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Sequential(\n",
              "        (conv2-0): Conv2d(64, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv2-1): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv2-2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Sequential(\n",
              "        (conv1-0): Conv2d(64, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv1-1): Conv2d(29, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv1-2): Conv2d(29, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Sequential(\n",
              "        (conv2-0): Conv2d(64, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv2-1): Conv2d(27, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv2-2): Conv2d(28, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Sequential(\n",
              "        (conv1-0): Conv2d(64, 38, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv1-1): Conv2d(38, 45, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (conv1-2): Conv2d(45, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Sequential(\n",
              "        (conv2-0): Conv2d(128, 63, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv2-1): Conv2d(63, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv2-2): Conv2d(57, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Sequential(\n",
              "          (0-0): Conv2d(64, 23, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (0-1): Conv2d(23, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        )\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Sequential(\n",
              "        (conv1-0): Conv2d(128, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv1-1): Conv2d(56, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv1-2): Conv2d(50, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Sequential(\n",
              "        (conv2-0): Conv2d(128, 43, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv2-1): Conv2d(43, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv2-2): Conv2d(48, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Sequential(\n",
              "        (conv1-0): Conv2d(128, 68, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv1-1): Conv2d(68, 112, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (conv1-2): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Sequential(\n",
              "        (conv2-0): Conv2d(256, 118, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv2-1): Conv2d(118, 109, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv2-2): Conv2d(109, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Sequential(\n",
              "          (0-0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (0-1): Conv2d(32, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        )\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Sequential(\n",
              "        (conv1-0): Conv2d(256, 111, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv1-1): Conv2d(111, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv1-2): Conv2d(100, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Sequential(\n",
              "        (conv2-0): Conv2d(256, 93, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv2-1): Conv2d(93, 105, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv2-2): Conv2d(105, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Sequential(\n",
              "        (conv1-0): Conv2d(256, 125, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv1-1): Conv2d(125, 203, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (conv1-2): Conv2d(203, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Sequential(\n",
              "        (conv2-0): Conv2d(512, 188, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv2-1): Conv2d(188, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv2-2): Conv2d(180, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Sequential(\n",
              "          (0-0): Conv2d(256, 75, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (0-1): Conv2d(75, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        )\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Sequential(\n",
              "        (conv1-0): Conv2d(512, 204, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv1-1): Conv2d(204, 193, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv1-2): Conv2d(193, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Sequential(\n",
              "        (conv2-0): Conv2d(512, 325, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv2-1): Conv2d(325, 348, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv2-2): Conv2d(348, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (fc-0): Linear(in_features=512, out_features=140, bias=False)\n",
              "    (fc-1): Linear(in_features=140, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cmodel = copy.deepcopy(compressor.compressed_model)\n",
        "cmodel.eval()\n",
        "for p in cmodel.parameters():\n",
        "  p.requires_grad = False\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ct9qGLAfLwVY",
        "outputId": "19faefce-24a8-44e3-cc71-8195a4a41058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device='cpu'\n",
        "x = torch.randn((1, 3, 224, 224))\n",
        "x.to(device)\n",
        "cmodel.to(device)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fMGMCJaPJrm",
        "outputId": "ec6f9d4a-3924-4af1-f8a3-69a2d71d2cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit _ = cmodel(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-6xvXAwOwNB",
        "outputId": "4177c099-fd62-4a96-feed-aa9d7238b9ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 70.8 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "for p in model.parameters():\n",
        "  p.requires_grad = False\n",
        "model.to(device)\n",
        "\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHZssi4fPFn_",
        "outputId": "96498fa6-6856-491a-b22b-d42aac4c8df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit _ = model(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fj108m6_P1cv",
        "outputId": "5a0c9bea-c951-4607-bf6b-2e353d5e31ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 88.7 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layers_to_fuse = []\n",
        "for block_id in ['1.0', '1.1', '2.0', '2.1', '3.0', '3.1', '4.0', '4.1']:\n",
        "  block_layers_to_fuse = [[f'layer{block_id}.conv1.conv1-2', f'layer{block_id}.bn1'],\n",
        "                          [f'layer{block_id}.conv2.conv2-2', f'layer{block_id}.bn2']]\n",
        "  layers_to_fuse += block_layers_to_fuse \n",
        "  \n",
        "\n",
        "torch.quantization.fuse_modules(compressor.compressed_model,\n",
        "                                layers_to_fuse,\n",
        "                                inplace = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syGE8laMRzQ7",
        "outputId": "d4529fc1-c8bc-4ffe-ae47-6e331d71d755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Sequential(\n",
              "    (conv1-0): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (conv1-1): Conv2d(3, 36, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (conv1-2): Conv2d(36, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  )\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Sequential(\n",
              "        (conv1-0): Conv2d(64, 44, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv1-1): Conv2d(44, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv1-2): ConvBn2d(\n",
              "          (0): Conv2d(36, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Sequential(\n",
              "        (conv2-0): Conv2d(64, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv2-1): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv2-2): ConvBn2d(\n",
              "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (bn2): Identity()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Sequential(\n",
              "        (conv1-0): Conv2d(64, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv1-1): Conv2d(29, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv1-2): ConvBn2d(\n",
              "          (0): Conv2d(29, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Sequential(\n",
              "        (conv2-0): Conv2d(64, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv2-1): Conv2d(27, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv2-2): ConvBn2d(\n",
              "          (0): Conv2d(28, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (bn2): Identity()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Sequential(\n",
              "        (conv1-0): Conv2d(64, 38, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv1-1): Conv2d(38, 45, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (conv1-2): ConvBn2d(\n",
              "          (0): Conv2d(45, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Sequential(\n",
              "        (conv2-0): Conv2d(128, 63, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv2-1): Conv2d(63, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv2-2): ConvBn2d(\n",
              "          (0): Conv2d(57, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (bn2): Identity()\n",
              "      (downsample): Sequential(\n",
              "        (0): Sequential(\n",
              "          (0-0): Conv2d(64, 23, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (0-1): Conv2d(23, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        )\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Sequential(\n",
              "        (conv1-0): Conv2d(128, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv1-1): Conv2d(56, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv1-2): ConvBn2d(\n",
              "          (0): Conv2d(50, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Sequential(\n",
              "        (conv2-0): Conv2d(128, 43, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv2-1): Conv2d(43, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv2-2): ConvBn2d(\n",
              "          (0): Conv2d(48, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (bn2): Identity()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Sequential(\n",
              "        (conv1-0): Conv2d(128, 68, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv1-1): Conv2d(68, 112, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (conv1-2): ConvBn2d(\n",
              "          (0): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Sequential(\n",
              "        (conv2-0): Conv2d(256, 118, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv2-1): Conv2d(118, 109, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv2-2): ConvBn2d(\n",
              "          (0): Conv2d(109, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (bn2): Identity()\n",
              "      (downsample): Sequential(\n",
              "        (0): Sequential(\n",
              "          (0-0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (0-1): Conv2d(32, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        )\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Sequential(\n",
              "        (conv1-0): Conv2d(256, 111, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv1-1): Conv2d(111, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv1-2): ConvBn2d(\n",
              "          (0): Conv2d(100, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Sequential(\n",
              "        (conv2-0): Conv2d(256, 93, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv2-1): Conv2d(93, 105, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv2-2): ConvBn2d(\n",
              "          (0): Conv2d(105, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (bn2): Identity()\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Sequential(\n",
              "        (conv1-0): Conv2d(256, 125, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv1-1): Conv2d(125, 203, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (conv1-2): ConvBn2d(\n",
              "          (0): Conv2d(203, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Sequential(\n",
              "        (conv2-0): Conv2d(512, 188, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv2-1): Conv2d(188, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv2-2): ConvBn2d(\n",
              "          (0): Conv2d(180, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (bn2): Identity()\n",
              "      (downsample): Sequential(\n",
              "        (0): Sequential(\n",
              "          (0-0): Conv2d(256, 75, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (0-1): Conv2d(75, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        )\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Sequential(\n",
              "        (conv1-0): Conv2d(512, 204, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv1-1): Conv2d(204, 193, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv1-2): ConvBn2d(\n",
              "          (0): Conv2d(193, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Sequential(\n",
              "        (conv2-0): Conv2d(512, 325, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (conv2-1): Conv2d(325, 348, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (conv2-2): ConvBn2d(\n",
              "          (0): Conv2d(348, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (bn2): Identity()\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (fc-0): Linear(in_features=512, out_features=140, bias=False)\n",
              "    (fc-1): Linear(in_features=140, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "abOWhbCOUM-q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}